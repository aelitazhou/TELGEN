{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77afc7cc",
   "metadata": {},
   "source": [
    "# generate topology for harp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f310e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle \n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7f3249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data should be put into the HARP codebase to run\n",
    "root = 'home/user/HARP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e0bf9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the whole asn first\n",
    "# this is for asn whole graph, you can also use asn with 98/510 nodes with node information saved in TE_TELGEN/raw/asn_graph\n",
    "path = 'raw/asn_graph/ASN2k.json'\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "data.keys()\n",
    "# keys are same as harp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "528c5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as harp (abilene, geant), no need to change\n",
    "data['directed'], data['multigraph'], data['graph'], data['nodes'], data['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fe957e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root+'topologies/asn1739/t1.json', 'w') as file:\n",
    "    json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "232b8d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check saved asn topology\n",
    "path = root+'topologies/asn1739/t1.json'\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766c1078",
   "metadata": {},
   "source": [
    "# generate pairs, traffic matrices and paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47fefad",
   "metadata": {},
   "source": [
    "### Data Format:\n",
    "#### 1) Traffic matrices: Numpy array of shape (num_pairs, 1)\n",
    "#### 2) Pairs: Numpy array of shape (num_pairs, 2)\n",
    "#### Note: the kth demand in the traffic matrix must correspond to the kth pair in the set of pairs file. This relation must be preserved for all snapshots. We suggest sorting the hash map (pairs/keys and values/demands) before separating.\n",
    "#### 3) Paths: By default, HARP computes K shortest paths and automatically puts them in the correct folders and format.\n",
    "#### If you wish to use your paths:\n",
    "#### i) create a Python dictionary where the keys are the pairs and the values are a list of K lists, where the inner lists are a sequence of edges.\n",
    "#### ii) For example: {(s, t): [[(s, a), (a, t)], [(s, a), (a, b), (b, t)]]}. \n",
    "#### iii) Put it inside topologies/paths_dict and name it: topo_name_K_paths_dict_cluster_num_cluster.pkl\n",
    "###### For example: abilene_8_paths_dict_cluster_0.pkl\n",
    "#### iiii) Make sure all pairs have the same number of paths (replicate if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c33df032",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'home/user/HARP/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a073f10a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "import networkx as nx\n",
    "\n",
    "\n",
    "def k_shortest_paths(G, source, target, k, weight=None):\n",
    "    return list(islice(nx.shortest_simple_paths(G, source, target, weight=weight), k))\n",
    "\n",
    "\n",
    "f = open('raw/asn_graph/ASN2k.json')\n",
    "G = json.load(f)\n",
    "\n",
    "asn_graph = nx.DiGraph()\n",
    "asn_graph.add_nodes_from([i['id'] for i in G['nodes']])\n",
    "asn_graph.add_edges_from([(i['source'], i['target']) for i in G['links']])\n",
    "print('Strongly connected:', nx.is_strongly_connected(asn_graph))\n",
    "print('# of nodes and edges:', asn_graph.number_of_nodes(), asn_graph.number_of_edges())\n",
    "print('Weighted:', nx.is_weighted(asn_graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27b481a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teal_harp_migrate: save the raw generated for teal and harp to migrate\n",
    "\n",
    "file = open('raw/raw/teal_harp_migrate/instance_0_stds.pkl', 'rb')\n",
    "std = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57d96979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pairs data of harp\n",
    "pairs = []\n",
    "tms = []\n",
    "paths = {}\n",
    "for i in std:\n",
    "    for j in i:\n",
    "        pairs.append(j[0])\n",
    "        tms.append(j[1])\n",
    "        k_paths = k_shortest_paths(asn_graph, j[0][0], j[0][1], k=4)\n",
    "        new_k_paths = []\n",
    "        for p in k_paths:\n",
    "            p = [(p[i], p[i+1]) for i in range(len(p)-1)]\n",
    "            new_k_paths.append(p)\n",
    "        paths[(j[0][0], j[0][1])] = new_k_paths\n",
    "pairs = np.array(pairs).reshape(-1, 2)\n",
    "tms = np.array(tms).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0de4698d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(root+'pairs/asn1739/t1.pkl', 'wb') as file:  \n",
    "    pickle.dump(pairs, file)\n",
    "with open(root+'traffic_matrices/asn1739/t1.pkl', 'wb') as file:  \n",
    "    pickle.dump(tms, file)\n",
    "with open(root+'topologies/paths_dict/asn1739_4_paths_dict_cluster_0.pkl', 'wb') as file:  \n",
    "    pickle.dump(paths, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda46f7f",
   "metadata": {},
   "source": [
    "### pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4450b93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check saved pairs, tms, paths\n",
    "file = open(root+'pairs/asn1739/t1.pkl', 'rb')\n",
    "pairs = pickle.load(file)\n",
    "pairs.shape, pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a32bbe39",
   "metadata": {},
   "source": [
    "### traffic matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a515b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check saved pairs, tms, paths\n",
    "file = open(root+'traffic_matrices/asn1739/t1.pkl', 'rb')\n",
    "tms = pickle.load(file)\n",
    "tms.shape, tms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8995b3",
   "metadata": {},
   "source": [
    "### paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7e1e1c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check saved pairs, tms, paths\n",
    "file = open(root+'topologies/paths_dict/asn1739_4_paths_dict_cluster_0.pkl', 'rb')\n",
    "paths = pickle.load(file)\n",
    "len(paths.keys()), paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd16a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipmgnn",
   "language": "python",
   "name": "ipmgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
