{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d879ffc",
   "metadata": {},
   "source": [
    "## generate erdos testing dataset for TELGEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c613b1ca-4366-4c13-b0d4-47e581195d5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from solver.linprog import linprog\n",
    "from tqdm import tqdm\n",
    "\n",
    "import gzip\n",
    "import pickle\n",
    "import torch\n",
    "from scipy.linalg import LinAlgWarning\n",
    "from scipy.optimize._optimize import OptimizeWarning\n",
    "# from scipy.optimize import OptimizeWarning\n",
    "import warnings\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "import random\n",
    "import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca5baa7a-a9fa-41b9-aa05-755f29c333b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "root = 'raw/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47db0a02",
   "metadata": {},
   "source": [
    "### Resource Allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa06ef7e",
   "metadata": {},
   "source": [
    "#### input: for one graph   \n",
    "#### G(V, E, c): random graph (strongly connected)\n",
    "#### (s, t, d) \\in [S, T, D]  \n",
    "#### for every (s, t, d), there is a set p \\in Pd (k-shortest path algorithm (4/5/6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d823c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c486ae",
   "metadata": {},
   "source": [
    "### generate and save connected and directed ER graph different nodes and p\n",
    "### generate capacities for these graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c136ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add capacity to one edge first: 13762\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 200 27524 0.7\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 87092\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 500 174184 0.7\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 349390\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 1000 698780 0.7\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 1399083\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 2000 2798166 0.7\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 15777\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 200 31554 0.8\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 99670\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 500 199340 0.8\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 399706\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 1000 799412 0.8\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 1599287\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 2000 3198574 0.8\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 17831\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 200 35662 0.9\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 112085\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 500 224170 0.9\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 449410\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 1000 898820 0.9\n",
      "----------------------------------------\n",
      "Add capacity to one edge first: 1798982\n",
      "Strongly connected: True\n",
      "# of nodes and edges, p: 2000 3597964 0.9\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2024)\n",
    "\n",
    "def generate_random_capacities(graph):\n",
    "    for u, v in graph.edges():\n",
    "        # Generate a random capacity for the edge (u, v)\n",
    "        capacity = random.uniform(1000, 5000)  # Adjust the range as needed\n",
    "        # Assign the capacity as an attribute to the edge\n",
    "        graph[u][v]['capacity'] = capacity\n",
    "        \n",
    "        \n",
    "# generate a directed er graph\n",
    "\n",
    "num_nodes = [200, 500, 1000, 2000] # number of nodes for creating ER random graph\n",
    "P = [0.7, 0.8, 0.9] # Probability for creating edges in ER random graph\n",
    "\n",
    "for p in P:\n",
    "    for n in num_nodes:\n",
    "        \n",
    "        # Generate an ER random graph same as nx.erdos_renyi_graph, but faster\n",
    "        er_graph = nx.fast_gnp_random_graph(n, p, seed=2024, directed=False)\n",
    "        \n",
    "        # Generate capacity for this graph\n",
    "        generate_random_capacities(er_graph)\n",
    "        Capacity = {}\n",
    "        for u, v in er_graph.edges():\n",
    "            Capacity[(u, v)] = er_graph[u][v]['capacity']\n",
    "        # save\n",
    "        with open(root+'erdos_graph/Edge_C_' + str(n) + 'n_' + str(p) + 'p.pkl', 'wb') as f:\n",
    "            pickle.dump(Capacity, f)\n",
    "        print('Add capacity to one edge first:', len(Capacity.keys()))\n",
    "        \n",
    "        # use undirected erdos graph and add .to_directed (symmetric)\n",
    "        G = er_graph.to_directed()\n",
    "        print('Strongly connected:', nx.is_strongly_connected(G))\n",
    "        print('# of nodes and edges, p:', G.number_of_nodes(), G.number_of_edges(), p)\n",
    "        # nx.draw(G, with_labels=True, node_color='lightgreen', arrows=True)    \n",
    "        # save\n",
    "        nx.write_graphml(G, root+'erdos_graph/er_graph_' + str(n) + 'n_' + str(p) + 'p.graphml')\n",
    "        print('----------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e86d830",
   "metadata": {},
   "source": [
    "### generate k-shortest path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35229b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "def k_shortest_paths(G, source, target, k, weight=None):\n",
    "    return list(islice(nx.shortest_simple_paths(G, source, target, weight=weight), k))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d1d42c",
   "metadata": {},
   "source": [
    "### Read all graphs and their capacities and load as a group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab660d25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph info 200 27524\n",
      "Connected: True\n",
      "Len capacity keys: 13762\n",
      "After adding Capacity info 200 27524\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 500 174184\n",
      "Connected: True\n",
      "Len capacity keys: 87092\n",
      "After adding Capacity info 500 174184\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 1000 698780\n",
      "Connected: True\n",
      "Len capacity keys: 349390\n",
      "After adding Capacity info 1000 698780\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 2000 2798166\n",
      "Connected: True\n",
      "Len capacity keys: 1399083\n",
      "After adding Capacity info 2000 2798166\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 200 31554\n",
      "Connected: True\n",
      "Len capacity keys: 15777\n",
      "After adding Capacity info 200 31554\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 500 199340\n",
      "Connected: True\n",
      "Len capacity keys: 99670\n",
      "After adding Capacity info 500 199340\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 1000 799412\n",
      "Connected: True\n",
      "Len capacity keys: 399706\n",
      "After adding Capacity info 1000 799412\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 2000 3198574\n",
      "Connected: True\n",
      "Len capacity keys: 1599287\n",
      "After adding Capacity info 2000 3198574\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 200 35662\n",
      "Connected: True\n",
      "Len capacity keys: 17831\n",
      "After adding Capacity info 200 35662\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 500 224170\n",
      "Connected: True\n",
      "Len capacity keys: 112085\n",
      "After adding Capacity info 500 224170\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 1000 898820\n",
      "Connected: True\n",
      "Len capacity keys: 449410\n",
      "After adding Capacity info 1000 898820\n",
      "Connected: True\n",
      "-------------------------------------\n",
      "Graph info 2000 3597964\n",
      "Connected: True\n",
      "Len capacity keys: 1798982\n",
      "After adding Capacity info 2000 3597964\n",
      "Connected: True\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#### select graphs ####\n",
    "num_nodes = [200, 500, 1000, 2000] # number of nodes for creating ER random graph\n",
    "P = [0.7, 0.8, 0.9] # Probability for creating edges in ER random graph\n",
    "ran_group = []\n",
    "ran_group_noC = []\n",
    "for p in P:\n",
    "    for n in num_nodes:\n",
    "        G = nx.read_graphml(root+'erdos_graph/er_graph_' + str(n) + 'n_' + str(p) + 'p.graphml')\n",
    "        ran_group_noC.append(G)\n",
    "        print('Graph info', G.number_of_nodes(), G.number_of_edges())\n",
    "        print('Connected:', nx.is_strongly_connected(G))\n",
    "        with open(root+'erdos_graph/Edge_C_' + str(n) + 'n_' + str(p) + 'p.pkl', 'rb') as f:\n",
    "            Edge_C = pickle.load(f)\n",
    "        print('Len capacity keys:', len(Edge_C.keys()))\n",
    "        g_test = nx.DiGraph(G)\n",
    "        for u, v in G.edges():\n",
    "            if (int(u), int(v)) in Edge_C.keys():\n",
    "                g_test.add_edge(u, v, weight=Edge_C[(int(u), int(v))])\n",
    "            else:\n",
    "                g_test.add_edge(u, v, weight=Edge_C[(int(v), int(u))])\n",
    "        ran_group.append(g_test)\n",
    "        print('After adding Capacity info', g_test.number_of_nodes(), g_test.number_of_edges())\n",
    "        print('Connected:', nx.is_strongly_connected(g_test))\n",
    "        print('-------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d886e6",
   "metadata": {},
   "source": [
    "## function define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5cefbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G: G(V, E, C)                           nx.weighted.graph\n",
    "# STD: demands align with ST pairs        list[([s1, t1], dmd1), ([s2, t2], dmd2),...], (string, int)\n",
    "# Pd: set of paths for every st pair      dict{[s1, t1]: [([path1], cost1), ([path2], cost2)...], [s2, t2]...}\n",
    "# # of std pairs = # of keys in Pd\n",
    "# k: k shortest path for every (s, t, d) tuple\n",
    "\n",
    "def generate_reallocation(G, STD, Pd, k):\n",
    "    \n",
    "    # constraint 1\n",
    "    A1 = []\n",
    "    for i in range(len(STD)):\n",
    "        a = np.zeros(len(STD)*k)\n",
    "        a[k*i: k*i+k] = 1\n",
    "        A1.append(a)\n",
    "    A1 = np.array(A1)\n",
    "    b1 = np.ones(len(STD))\n",
    "\n",
    "    # constrain 2\n",
    "    edges_list = list(G.edges())\n",
    "    A2 = np.zeros((G.number_of_edges(), len(STD)*k))\n",
    "\n",
    "    for i in range(len(STD)):\n",
    "        paths = Pd[tuple(STD[i][0])] # possible paths\n",
    "        for j in range(k):\n",
    "            p = paths[j]   # path[j] is the path\n",
    "            for n in range(len(p)-1):\n",
    "                if (p[n], p[n+1]) in edges_list:\n",
    "                    A2[edges_list.index((p[n], p[n+1]))][k*i+j] = STD[i][1]\n",
    "                else:\n",
    "                    continue  \n",
    "    b2 = np.array(list(nx.get_edge_attributes(G,'weight').values()))\n",
    "    zero_row_indices = np.where(A2.any(axis=1)==0)[0]\n",
    "    A2 = np.delete(A2, zero_row_indices, axis=0)\n",
    "    b2 = np.delete(b2, zero_row_indices, axis=0)\n",
    "\n",
    "    for i in range(A2.shape[0]):\n",
    "        A2[i] = A2[i]/b2[i]\n",
    "        b2[i] = b2[i]/b2[i]\n",
    "    \n",
    "    # obj\n",
    "    c = -1*np.concatenate([np.ones(k)*STD[i][1] for i in range(len(STD))])\n",
    "        \n",
    "    return A1, b1, A2, b2, c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b7ecac",
   "metadata": {},
   "source": [
    "## test dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ecc353b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      message: Optimization terminated successfully.\n",
      "      success: True\n",
      "       status: 0\n",
      "          fun: -31349.513682428136\n",
      "            x: [ 2.109e-01  2.156e-01 ...  2.166e-01  1.963e-01]\n",
      "          nit: 7\n",
      " intermediate: []\n",
      "      message: Optimization terminated successfully.\n",
      "      success: True\n",
      "       status: 0\n",
      "          fun: -35319.265433685934\n",
      "            x: [ 2.479e-01  1.630e-01 ...  1.652e-01  2.416e-01]\n",
      "          nit: 7\n",
      " intermediate: []\n",
      "      message: Optimization terminated successfully.\n",
      "      success: True\n",
      "       status: 0\n",
      "          fun: -25084.20758680875\n",
      "            x: [ 2.199e-01  2.097e-01 ...  2.067e-01  1.909e-01]\n",
      "          nit: 7\n",
      " intermediate: []\n",
      "      message: Optimization terminated successfully.\n",
      "      success: True\n",
      "       status: 0\n",
      "          fun: -27989.14581541008\n",
      "            x: [ 2.184e-01  1.853e-01 ...  1.904e-01  1.925e-01]\n",
      "          nit: 7\n",
      " intermediate: []\n",
      "Graph info and average time used: (200, 35662, 0.004581928253173828)\n",
      "Graph info and average time used: (500, 224170, 0.004549741744995117)\n",
      "Graph info and average time used: (1000, 898820, 0.004460811614990234)\n",
      "Graph info and average time used: (2000, 3597964, 0.004473447799682617)\n"
     ]
    }
   ],
   "source": [
    "### gen train ####\n",
    "import time\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "random.seed(2024)\n",
    "np.random.seed(2024)\n",
    "\n",
    "\n",
    "pkg_idx = 0              # instance index for your data generation\n",
    "success_cnt = 0\n",
    "fail_cnt = 0\n",
    "bounds = (0., 1.)\n",
    "\n",
    "max_iter = 15000\n",
    "num = 1                  # number of instance generated\n",
    "\n",
    "k = 4                    # k-shortest path\n",
    "max_d = 5000             # demand max value\n",
    "min_d = 1000             # demand min value\n",
    "\n",
    "number_of_st = 10        # number of st pairs\n",
    "\n",
    "graph_info = []\n",
    "for g in range(len(ran_group)):\n",
    "    stds = []\n",
    "    ips = []\n",
    "    success_cnt = 0\n",
    "    times = []\n",
    "    for n in range(num+200): # in case failsure case\n",
    "        \n",
    "        # generate st pairs with demand value \n",
    "        std = []\n",
    "        Pd = {}\n",
    "        count_std = 0\n",
    "        while count_std != number_of_st:\n",
    "            st = np.random.choice(ran_group[g].nodes(), 2, replace=False)\n",
    "            d = random.uniform(min_d, max_d)\n",
    "            k_paths = k_shortest_paths(ran_group_noC[g], st[0], st[1], k=k)\n",
    "            if len(k_paths) != k:\n",
    "                continue\n",
    "            else:\n",
    "                Pd[(st[0], st[1])] = k_paths\n",
    "                std.append((st, d))\n",
    "                count_std += 1\n",
    "\n",
    "        A1, b1, A2, b2, c = generate_reallocation(ran_group[g], std, Pd, k)\n",
    "        A = np.vstack([A1, A2])\n",
    "        b = np.hstack([b1, b2])\n",
    "        \n",
    "        n_time = time.time()\n",
    "        try:\n",
    "            A_eq = None\n",
    "            b_eq = None\n",
    "            A_ub = A\n",
    "            b_ub = b\n",
    "            res = linprog(c, A_ub=A_ub, b_ub=b_ub, A_eq=A_eq, b_eq=b_eq, bounds=bounds, \n",
    "                          method='interior-point')\n",
    "            times.append(time.time()-n_time)\n",
    "            print(res)\n",
    "        except (LinAlgWarning, OptimizeWarning, AssertionError):\n",
    "            fail_cnt += 1\n",
    "            continue\n",
    "        else:\n",
    "            if res.success and not np.isnan(res.fun):\n",
    "                ips.append((torch.from_numpy(A).to(torch.float), torch.from_numpy(b).to(torch.float), torch.from_numpy(c).to(torch.float)))\n",
    "                success_cnt += 1\n",
    "                stds.append(std)\n",
    "        if success_cnt == num:\n",
    "            break\n",
    "\n",
    "    with open(root+'/raw/instance_'+str(pkg_idx)+'_stds.pkl','wb') as f:\n",
    "        pickle.dump(stds, f)\n",
    "    with gzip.open(f'{root}/raw/instance_{pkg_idx}.pkl.gz', \"wb\") as file:\n",
    "        pickle.dump(ips, file)\n",
    "    pkg_idx += 1\n",
    "#     print('-----------------------------------------')\n",
    "#     print('Graph finished info:', ran_group[g].number_of_nodes(), ran_group[g].number_of_edges())\n",
    "#     print('Average time used:', sum(times)/len(times))\n",
    "#     print('-----------------------------------------')\n",
    "    graph_info.append((ran_group[g].number_of_nodes(), ran_group[g].number_of_edges(), sum(times)/len(times)))\n",
    "\n",
    "np.save(root+'/raw/erdos_test_'+str(number_of_st)+'st_info', graph_info)\n",
    "for i in graph_info:\n",
    "    print('Graph info and average time used:', i)\n",
    "\n",
    "    \n",
    "    \n",
    "warnings.resetwarnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93f01e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ipmgnn",
   "language": "python",
   "name": "ipmgnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
